{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9277c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8fa490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # cuda test\n",
    "print(torch.__version__)          # version test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a0a74",
   "metadata": {},
   "source": [
    "HNSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac3b7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNSW:\n",
    "    def __init__(self, max_layers=3, ef_construction=80, M=12, ef_search=50, device='cuda'):\n",
    "        self.max_layers = max_layers\n",
    "        self.ef_construction = ef_construction\n",
    "        self.M = M\n",
    "        self.ef_search = ef_search\n",
    "        self.device = device\n",
    "        self.enter_point = None\n",
    "        self.graphs = [defaultdict(list) for _ in range(max_layers)]\n",
    "        self.vectors = None\n",
    "        self.cluster_centers = None\n",
    "        self.cluster_assignments = None\n",
    "    \n",
    "    def _select_neighbors_simple(self, q, candidates, layer, K):\n",
    "        if len(candidates) <= K:\n",
    "            return candidates\n",
    "        candidate_vectors = self.vectors[torch.tensor(candidates, device=self.device)]\n",
    "        # distances = torch.norm(candidate_vectors - q, dim=1)\n",
    "        distances = torch.cdist(q.unsqueeze(0), candidate_vectors).squeeze(0)  # faster than norm\n",
    "        _, indices = torch.topk(distances, K, largest=False)\n",
    "        return [candidates[i] for i in indices.cpu().numpy()]\n",
    "    \n",
    "    def _search_layer(self, q, ep, ef, layer):\n",
    "        visited = set(ep)\n",
    "        candidates = ep.copy()\n",
    "        heap = []\n",
    "        \n",
    "        for node in ep:\n",
    "            dist = torch.norm(self.vectors[node] - q)\n",
    "            heap.append((dist, node))\n",
    "        \n",
    "        heap.sort()\n",
    "        result = ep.copy()\n",
    "        \n",
    "        while candidates:\n",
    "            current = candidates.pop(0)\n",
    "            if len(result) >= ef and heap[0][0] > heap[ef-1][0]:\n",
    "                break\n",
    "                \n",
    "            for neighbor in self.graphs[layer][current]:\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    dist = torch.norm(self.vectors[neighbor] - q)\n",
    "                    if len(result) < ef or dist < heap[-1][0]:\n",
    "                        result.append(neighbor)\n",
    "                        candidates.append(neighbor)\n",
    "                        heap.append((dist, neighbor))\n",
    "                        heap.sort()\n",
    "                        if len(heap) > ef:\n",
    "                            heap = heap[:ef]\n",
    "        \n",
    "        return result[:ef]\n",
    "    \n",
    "    def _get_random_layer(self):\n",
    "        return min(int(-math.log(random.random()) * 1.0), self.max_layers - 1)\n",
    "    \n",
    "    def build_index(self, vectors):\n",
    "        start_time = time.time()\n",
    "        self.vectors = torch.tensor(vectors, device=self.device)\n",
    "        N, D = self.vectors.shape\n",
    "        self.enter_point = random.randint(0, N-1)\n",
    "        \n",
    "        for node in range(N):\n",
    "            self.graphs[0][node] = []\n",
    "        \n",
    "        for node in range(N):\n",
    "            l = self._get_random_layer()\n",
    "            ep = [self.enter_point]\n",
    "            \n",
    "            for layer in reversed(range(l+1)):\n",
    "                ep = self._search_layer(self.vectors[node], ep, self.ef_construction, layer)\n",
    "                neighbors = self._select_neighbors_simple(self.vectors[node], ep, layer, self.M)\n",
    "                \n",
    "                for neighbor in neighbors:\n",
    "                    if node not in self.graphs[layer][neighbor] and neighbor != node:\n",
    "                        self.graphs[layer][neighbor].append(node)\n",
    "                        self.graphs[layer][node].append(neighbor)\n",
    "                \n",
    "                for n in neighbors:\n",
    "                    if len(self.graphs[layer][n]) > self.M * 2:\n",
    "                        self.graphs[layer][n] = self._select_neighbors_simple(\n",
    "                            self.vectors[n], self.graphs[layer][n], layer, self.M)\n",
    "            \n",
    "            if l > 0:\n",
    "                self.enter_point = node\n",
    "        \n",
    "        build_time = time.time() - start_time\n",
    "        return build_time\n",
    "    \n",
    "    def kmeans(self, K, max_iters=30):\n",
    "        start_time = time.time()\n",
    "        N, D = self.vectors.shape\n",
    "        centroids = self.vectors[torch.randperm(N)[:K]].clone()\n",
    "        \n",
    "        for _ in range(max_iters):\n",
    "            distances = torch.cdist(self.vectors, centroids)\n",
    "            cluster_ids = torch.argmin(distances, dim=1)\n",
    "            \n",
    "            new_centroids = torch.zeros_like(centroids)\n",
    "            counts = torch.zeros(K, device=self.device)\n",
    "            \n",
    "            for k in range(K):\n",
    "                mask = cluster_ids == k\n",
    "                if mask.any():\n",
    "                    new_centroids[k] = self.vectors[mask].mean(dim=0)\n",
    "                    counts[k] = mask.sum()\n",
    "            \n",
    "            empty_clusters = counts == 0\n",
    "            if empty_clusters.any():\n",
    "                new_centroids[empty_clusters] = self.vectors[torch.randperm(N)[:empty_clusters.sum()]]\n",
    "            \n",
    "            if torch.allclose(centroids, new_centroids, rtol=1e-4):\n",
    "                break\n",
    "                \n",
    "            centroids = new_centroids\n",
    "        \n",
    "        self.cluster_centers = centroids\n",
    "        self.cluster_assignments = cluster_ids\n",
    "        return time.time() - start_time\n",
    "    \n",
    "    def search(self, query, K):\n",
    "        start_time = time.time()\n",
    "        query = torch.tensor(query, device=self.device)\n",
    "        ep = [self.enter_point]\n",
    "        \n",
    "        for layer in reversed(range(self.max_layers)):\n",
    "            ep = self._search_layer(query, ep, self.ef_search, layer)\n",
    "        \n",
    "        candidates = ep\n",
    "        candidate_vectors = self.vectors[torch.tensor(candidates, device=self.device)]\n",
    "        distances = torch.norm(candidate_vectors - query, dim=1)\n",
    "        _, indices = torch.topk(distances, min(K, len(candidates)), largest=False)\n",
    "        \n",
    "        search_time = time.time() - start_time\n",
    "        return [candidates[i] for i in indices.cpu().numpy()], search_time\n",
    "    \n",
    "    def search_with_clusters(self, query, K, cluster_K=2):\n",
    "        start_time = time.time()\n",
    "        if self.cluster_centers is None:\n",
    "            return self.search(query, K)\n",
    "        \n",
    "        query = torch.tensor(query, device=self.device)\n",
    "        cluster_distances = torch.norm(self.cluster_centers - query, dim=1)\n",
    "        _, closest_clusters = torch.topk(cluster_distances, cluster_K, largest=False)\n",
    "        \n",
    "        candidates = []\n",
    "        for cluster_id in closest_clusters:\n",
    "            mask = self.cluster_assignments == cluster_id\n",
    "            candidates.extend(torch.where(mask)[0].tolist())\n",
    "        \n",
    "        candidate_vectors = self.vectors[torch.tensor(candidates, device=self.device)]\n",
    "        distances = torch.norm(candidate_vectors - query, dim=1)\n",
    "        _, indices = torch.topk(distances, min(K, len(candidates)), largest=False)\n",
    "        \n",
    "        search_time = time.time() - start_time\n",
    "        return [candidates[i] for i in indices.cpu().numpy()], search_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc5151ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ann_performance(A, X, K, num_queries=10):\n",
    "    \"\"\"\n",
    "    Compare performance of GPU/CPU HNSW and exact KNN\n",
    "    \n",
    "    Args:\n",
    "        A: Dataset (N x D numpy array)\n",
    "        X: Query vector (D,)\n",
    "        K: Number of nearest neighbors to return\n",
    "        num_queries: Number of test queries\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains build time, search times and recall for each method\n",
    "    \"\"\"\n",
    "    # Convert to numpy array for consistency\n",
    "    if isinstance(A, torch.Tensor):\n",
    "        A = A.cpu().numpy()\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        X = X.cpu().numpy()\n",
    "    \n",
    "    print(f\"\\nStarting performance comparison (Dataset: {A.shape[0]} vectors of dim {A.shape[1]}, K={K}, queries={num_queries})\")\n",
    "    results = {\n",
    "        'hnsw_gpu': {'build_time': 0, 'search_times': [], 'recall': 0},\n",
    "        'hnsw_cpu': {'build_time': 0, 'search_times': [], 'recall': 0},\n",
    "        'exact_knn': {'build_time': 0, 'search_times': [], 'recall': 1.0}\n",
    "    }\n",
    "    \n",
    "    # 1. Test GPU HNSW\n",
    "    print(\"\\n[1/3] Building GPU HNSW index...\")\n",
    "    torch.cuda.synchronize()\n",
    "    hnsw_gpu = HNSW(device='cuda')\n",
    "    build_time = hnsw_gpu.build_index(A)\n",
    "    results['hnsw_gpu']['build_time'] = build_time\n",
    "    print(f\"GPU HNSW index built in: {build_time:.4f}s\")\n",
    "    \n",
    "    # 2. Test CPU HNSW\n",
    "    print(\"\\n[2/3] Building CPU HNSW index...\")\n",
    "    hnsw_cpu = HNSW(device='cpu')\n",
    "    build_time = hnsw_cpu.build_index(A)\n",
    "    results['hnsw_cpu']['build_time'] = build_time\n",
    "    print(f\"CPU HNSW index built in: {build_time:.4f}s\")\n",
    "    \n",
    "    # 3. Exact KNN (no build time, only search)\n",
    "    print(\"\\n[3/3] Preparing exact KNN tests...\")\n",
    "    A_tensor = torch.tensor(A, device='cuda')\n",
    "    X_tensor = torch.tensor(X, device='cuda')\n",
    "    \n",
    "    # Run multiple queries for averaging\n",
    "    exact_results = []\n",
    "    print(\"\\nRunning exact KNN queries...\")\n",
    "    for _ in tqdm(range(num_queries), desc=\"Exact KNN Progress\"):\n",
    "        start_time = time.time()\n",
    "        distances = torch.norm(A_tensor - X_tensor, dim=1)\n",
    "        _, indices = torch.topk(distances, K, largest=False)\n",
    "        search_time = time.time() - start_time\n",
    "        results['exact_knn']['search_times'].append(search_time)\n",
    "        exact_results.append(indices.cpu().numpy())\n",
    "    \n",
    "    # Calculate recall rates\n",
    "    print(\"\\nRunning HNSW queries and calculating recall...\")\n",
    "    for i in tqdm(range(num_queries), desc=\"Overall Progress\"):\n",
    "        # GPU HNSW query\n",
    "        gpu_result, search_time = hnsw_gpu.search(X, K)\n",
    "        results['hnsw_gpu']['search_times'].append(search_time)\n",
    "        results['hnsw_gpu']['recall'] += calculate_recall(gpu_result, exact_results[0], K)\n",
    "        \n",
    "        # CPU HNSW query\n",
    "        cpu_result, search_time = hnsw_cpu.search(X, K)\n",
    "        results['hnsw_cpu']['search_times'].append(search_time)\n",
    "        results['hnsw_cpu']['recall'] += calculate_recall(cpu_result, exact_results[0], K)\n",
    "        \n",
    "        # Show interim progress\n",
    "        if (i+1) % max(1, num_queries//5) == 0 or (i+1) == num_queries:\n",
    "            current_gpu_time = sum(results['hnsw_gpu']['search_times']) / len(results['hnsw_gpu']['search_times'])\n",
    "            current_cpu_time = sum(results['hnsw_cpu']['search_times']) / len(results['hnsw_cpu']['search_times'])\n",
    "            current_exact_time = sum(results['exact_knn']['search_times']) / len(results['exact_knn']['search_times'])\n",
    "            print(f\"\\n--- Progress {i+1}/{num_queries} ---\")\n",
    "            print(f\"Current avg query times: GPU HNSW={current_gpu_time:.6f}s, CPU HNSW={current_cpu_time:.6f}s, Exact KNN={current_exact_time:.6f}s\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    for method in results:\n",
    "        if method != 'exact_knn':\n",
    "            results[method]['recall'] /= num_queries\n",
    "        results[method]['avg_search_time'] = sum(results[method]['search_times']) / num_queries\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_recall(ann_result, knn_result, K):\n",
    "    ann_set = set(ann_result[:K])\n",
    "    knn_set = set(knn_result[:K])\n",
    "    return len(ann_set & knn_set) / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28997310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting performance comparison (Dataset: 100 vectors of dim 32, K=3, queries=1)\n",
      "\n",
      "[1/3] Building GPU HNSW index...\n",
      "GPU HNSW index built in: 21.6745s\n",
      "\n",
      "[2/3] Building CPU HNSW index...\n",
      "CPU HNSW index built in: 0.6772s\n",
      "\n",
      "[3/3] Preparing exact KNN tests...\n",
      "\n",
      "Running exact KNN queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exact KNN Progress: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running HNSW queries and calculating recall...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Progress 1/1 ---\n",
      "Current avg query times: GPU HNSW=0.409381s, CPU HNSW=0.012204s, Exact KNN=0.000000s\n",
      "\n",
      "=== Final Performance Results ===\n",
      "Dataset: 100 vectors of dim 32 | K=3 | Test queries=1\n",
      "\n",
      "=== Performance Summary ===\n",
      "Method          Build Time(s)   Avg Query Time(s) Recall         \n",
      "hnsw_gpu        21.674493       0.409381        0.666667       \n",
      "hnsw_cpu        0.677247        0.012204        0.666667       \n",
      "exact_knn       0.000000        0.000000        1.000000       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate random data\n",
    "N = 100  # Number of vectors\n",
    "D = 32    # Dimension\n",
    "K = 3      # Number of clusters/top-K\n",
    "A = np.random.randn(N, D).astype(np.float32)\n",
    "X = np.random.randn(D).astype(np.float32)\n",
    "num_queries = 1  # Number of queries\n",
    "# Run comparison\n",
    "results = compare_ann_performance(A, X, K, num_queries=num_queries)\n",
    "    \n",
    "# Print final results\n",
    "print(\"\\n=== Final Performance Results ===\")\n",
    "print(f\"Dataset: {N} vectors of dim {D} | K={K} | Test queries={num_queries}\")\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "print(\"{:<15} {:<15} {:<15} {:<15}\".format(\n",
    "    \"Method\", \"Build Time(s)\", \"Avg Query Time(s)\", \"Recall\"))\n",
    "    \n",
    "for method, data in results.items():\n",
    "    print(\"{:<15} {:<15.6f} {:<15.6f} {:<15.6f}\".format(\n",
    "        method,\n",
    "        data['build_time'],\n",
    "        data['avg_search_time'],\n",
    "        data['recall']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
